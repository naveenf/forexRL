{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸš€ Forex Trading System - PPO Training\n",
    "\n",
    "**Goal**: Train AI to make $100 profit in 4 candles (1 hour)\n",
    "\n",
    "**Algorithm**: PPO with Gemma 2B model  \n",
    "**Duration**: 12-24 hours on GPU  \n",
    "**Target**: 500k timesteps\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ğŸ”§ 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU availability\nimport torch\nimport os\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"ğŸ® GPU Available: {gpu_name}\")\n    print(f\"   Memory: {gpu_memory:.1f} GB\")\nelse:\n    print(\"âš ï¸ No GPU detected - training will be very slow!\")\n    print(\"Go to Runtime â†’ Change Runtime Type â†’ Hardware Accelerator â†’ GPU\")\n\nprint(f\"\\nğŸ“ Current directory: {os.getcwd()}\")\nprint(f\"ğŸ“‚ Files available: {os.listdir()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Create necessary directories\n!mkdir -p src config training logs models/checkpoints models/final data\n\nprint(\"âœ… Directories created\")\nprint(\"\")\nprint(\"ğŸ“ Now upload your files using the file browser (folder icon on left):\")\nprint(\"   - data_manager.py â†’ src/\")\nprint(\"   - environment.py â†’ src/\")\nprint(\"   - train_ppo.py â†’ training/\")\nprint(\"   - training.yaml â†’ config/\")\nprint(\"   - requirements_colab.txt â†’ root\")\nprint(\"   - EURUSD_M15.csv â†’ data/\")\nprint(\"   - AUDCHF_M15.csv â†’ data/\")\nprint(\"   - USDJPY_M15.csv â†’ data/\")\nprint(\"\")\nprint(\"â³ After uploading, run the next cell...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify file uploads\n",
    "import os\n",
    "\n",
    "required_files = {\n",
    "    'src/data_manager.py': 'Data Manager',\n",
    "    'src/environment.py': 'Trading Environment',  \n",
    "    'training/train_ppo.py': 'Training Script',\n",
    "    'config/training.yaml': 'Training Config',\n",
    "    'requirements_colab.txt': 'Requirements'\n",
    "}\n",
    "\n",
    "csv_files = {\n",
    "    'data/EURUSD_M15.csv': 'EURUSD Historical Data',\n",
    "    'data/AUDCHF_M15.csv': 'AUDCHF Historical Data',\n",
    "    'data/USDJPY_M15.csv': 'USDJPY Historical Data'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Required Files Status:\")\n",
    "all_uploaded = True\n",
    "\n",
    "for file_path, description in required_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"âœ… {description}: {file_path} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"âŒ {description}: {file_path} - MISSING\")\n",
    "        all_uploaded = False\n",
    "\n",
    "print(\"\\nğŸ“Š CSV Data Files Status:\")\n",
    "csv_count = 0\n",
    "for file_path, description in csv_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path) / 1024 / 1024  # MB\n",
    "        print(f\"âœ… {description}: {file_path} ({size:.1f} MB)\")\n",
    "        csv_count += 1\n",
    "    else:\n",
    "        print(f\"âš ï¸ {description}: {file_path} - OPTIONAL (will use sample data)\")\n",
    "\n",
    "if all_uploaded:\n",
    "    print(f\"\\nğŸ‰ All required files uploaded! Found {csv_count}/3 CSV files.\")\n",
    "    if csv_count == 3:\n",
    "        print(\"ğŸ¯ Ready for training with YOUR historical data!\")\n",
    "    else:\n",
    "        print(\"ğŸ“Š Will use sample data for missing pairs\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Please upload missing files before continuing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": "## ğŸ“¦ 2. Install Dependencies\n\n**Choose ONE method below:**\n- **Method 1**: Simple installation (recommended)\n- **Method 2**: Advanced installation (if Method 1 fails)\n- **Method 3**: Emergency fix (if both fail)"
  },
  {
   "cell_type": "code",
   "id": "0w4xvh5gddgm",
   "source": "# SIMPLE & RELIABLE Installation (Use this FIRST!)\nprint(\"ğŸ”§ SIMPLE INSTALLATION METHOD\")\nprint(\"=\" * 40)\nprint(\"This method has the highest success rate in Google Colab\")\n\n# Step 1: Clean install\nprint(\"\\nğŸ§¹ Step 1: Clean previous installations...\")\n!pip uninstall -y stable-baselines3 gymnasium sb3-contrib -q\n\n# Step 2: Install with specific working versions\nprint(\"\\nğŸ“¦ Step 2: Installing with proven working versions...\")\n!pip install -q gymnasium==0.29.1\n!pip install -q stable-baselines3==2.0.0\n\n# Step 3: Install additional dependencies\nprint(\"\\nğŸ”§ Step 3: Installing additional packages...\")\n!pip install -q torch numpy pandas pyyaml transformers\n\n# Step 4: Test installation\nprint(\"\\nğŸ§ª Step 4: Testing installation...\")\ntry:\n    import gymnasium as gym\n    import stable_baselines3 as sb3\n    import torch\n    \n    print(\"âœ… SUCCESS! All packages installed correctly\")\n    print(f\"   Gymnasium: {gym.__version__}\")\n    print(f\"   Stable-Baselines3: {sb3.__version__}\")\n    print(f\"   PyTorch: {torch.__version__}\")\n    print(\"\\nğŸ¯ Ready to proceed with training!\")\n    \nexcept ImportError as e:\n    print(f\"âŒ Installation failed: {e}\")\n    print(\"ğŸ”„ Try the advanced installation method in the next cell\")\n\nprint(\"\\n\" + \"=\" * 40)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Install packages with ROBUST error handling\nprint(\"ğŸ“¦ Installing dependencies with crash-resistant method...\")\nprint(\"âš ï¸ This handles Colab-specific installation issues\")\n\n# Step 1: Core packages first\nprint(\"\\nğŸ”§ Step 1: Installing core ML packages...\")\n!pip install -q torch numpy pandas scipy matplotlib pyyaml tqdm psutil\nprint(\"âœ… Core packages installed\")\n\n# Step 2: RL framework with proper error handling\nprint(\"\\nğŸ¤– Step 2: Installing RL framework (stable-baselines3)...\")\n\n# Install Gymnasium first\nprint(\"ğŸ”„ Installing Gymnasium...\")\n!pip install -q \"gymnasium>=0.28.0,<0.30.0\"\nprint(\"âœ… Gymnasium installed\")\n\n# Install stable-baselines3 with multiple fallback methods\nprint(\"ğŸ”„ Installing stable-baselines3...\")\ntry:\n    # Method 1: Standard installation\n    !pip install -q \"stable-baselines3>=1.8.0\"\n    \n    # Test if it actually works\n    import stable_baselines3\n    print(\"âœ… stable-baselines3 installed successfully\")\n    \nexcept Exception as e:\n    print(f\"âš ï¸ Standard install failed: {e}\")\n    print(\"ğŸ”„ Trying alternative installation...\")\n    \n    # Method 2: Install specific working version\n    !pip install -q stable-baselines3==2.0.0\n    \n    try:\n        import stable_baselines3\n        print(\"âœ… stable-baselines3 v2.0.0 installed\")\n    except Exception as e2:\n        print(f\"âš ï¸ Version 2.0.0 failed: {e2}\")\n        print(\"ğŸ”„ Final attempt with latest...\")\n        \n        # Method 3: Latest version with force reinstall\n        !pip install --force-reinstall -q stable-baselines3\n        \n        try:\n            import stable_baselines3\n            print(\"âœ… stable-baselines3 force installed\")\n        except Exception as e3:\n            print(f\"âŒ All installation methods failed: {e3}\")\n            print(\"ğŸ”„ SOLUTION: Restart runtime (Ctrl+M .) and run this cell again\")\n\nprint(\"\\nğŸ“ˆ Step 3: Installing optional packages...\")\noptional_packages = [\"transformers\", \"accelerate\", \"seaborn\"]\n\nfor package in optional_packages:\n    try:\n        !pip install -q {package}\n        print(f\"âœ… {package} installed\")\n    except:\n        print(f\"âš ï¸ {package} failed (optional)\")\n\nprint(\"\\nğŸ‰ Installation phase complete!\")\nprint(\"ğŸ”„ If stable-baselines3 failed, run the emergency fix cell below\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TA-Lib CAREFULLY (alternative to crashes)\n",
    "print(\"ğŸ“ˆ Installing TA-Lib - CRASH-RESISTANT METHOD\")\n",
    "print(\"â³ This will take 2-3 minutes but should not crash...\")\n",
    "\n",
    "try:\n",
    "    # Method 1: Try direct pip install first\n",
    "    print(\"ğŸ”„ Trying direct pip install...\")\n",
    "    !pip install -q TA-Lib\n",
    "    print(\"âœ… TA-Lib installed via pip\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Direct install failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Method 2: Install from source if pip fails\n",
    "        print(\"ğŸ”„ Trying source compilation...\")\n",
    "        !wget -q http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "        !tar -xzf ta-lib-0.4.0-src.tar.gz > /dev/null 2>&1\n",
    "        \n",
    "        # Use background compilation to avoid hanging\n",
    "        !cd ta-lib && ./configure --prefix=/usr > /dev/null 2>&1 && make > /dev/null 2>&1 && make install > /dev/null 2>&1\n",
    "        !pip install -q TA-Lib\n",
    "        \n",
    "        print(\"âœ… TA-Lib compiled and installed from source\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"âš ï¸ Source compilation failed: {e2}\")\n",
    "        print(\"ğŸ“Š Will use basic indicators instead - training will still work!\")\n",
    "\n",
    "# Clean up\n",
    "!rm -rf ta-lib* > /dev/null 2>&1\n",
    "\n",
    "print(\"\\nğŸ¯ TA-Lib installation complete (or gracefully skipped)\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "btnlfgz3959",
   "source": "# EMERGENCY FIX: Install stable-baselines3 if previous cell failed\nprint(\"ğŸš¨ EMERGENCY FIX FOR STABLE-BASELINES3\")\nprint(\"=\" * 50)\nprint(\"Run this cell if the previous installation failed\")\n\ntry:\n    # Test if stable-baselines3 is already working\n    import stable_baselines3\n    print(\"âœ… stable-baselines3 already working!\")\n    print(f\"   Version: {stable_baselines3.__version__}\")\n    \nexcept ImportError:\n    print(\"ğŸ”„ Installing stable-baselines3 with emergency method...\")\n    \n    # Method 1: Restart and install with specific version\n    print(\"\\nğŸ”§ Method 1: Installing specific stable version...\")\n    !pip uninstall -y stable-baselines3 gymnasium\n    !pip install -q gymnasium==0.29.1\n    !pip install -q stable-baselines3==2.0.0\n    \n    try:\n        import stable_baselines3\n        print(\"âœ… Method 1 successful! stable-baselines3 installed\")\n        print(f\"   Version: {stable_baselines3.__version__}\")\n    except ImportError:\n        # Method 2: Install dependencies separately  \n        print(\"\\nğŸ”§ Method 2: Installing dependencies separately...\")\n        !pip install -q torch\n        !pip install -q numpy\n        !pip install -q gymnasium\n        !pip install -q stable-baselines3\n        \n        try:\n            import stable_baselines3\n            print(\"âœ… Method 2 successful! stable-baselines3 installed\")\n        except ImportError:\n            # Method 3: Manual solution\n            print(\"\\nâŒ Emergency methods failed\")\n            print(\"\\nğŸ”§ MANUAL SOLUTION:\")\n            print(\"1. Go to Runtime â†’ Restart Runtime\")\n            print(\"2. Wait for restart to complete\")\n            print(\"3. Re-run all cells from the beginning\") \n            print(\"4. This often resolves Colab package conflicts\")\n            print(\"\\nğŸ”„ After restart, run this command first:\")\n            print(\"   !pip install gymnasium==0.29.1 stable-baselines3==2.0.0\")\n\nprint(\"\\nğŸ¯ Emergency fix complete - try the import test cell again!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"ğŸ§ª Testing imports...\")\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "    import stable_baselines3\n",
    "    import torch\n",
    "    import transformers\n",
    "    print(\"âœ… Core RL packages imported\")\n",
    "    \n",
    "    # Test custom modules\n",
    "    import sys\n",
    "    sys.path.append('src')\n",
    "    \n",
    "    from data_manager import DataManager\n",
    "    from environment import MultiPairForexEnv\n",
    "    print(\"âœ… Custom forex modules imported\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ All imports successful! Ready for training.\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"Please check file uploads and package installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## ğŸ“Š 3. Data Preparation & Environment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data manager and environment with CSV loading\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from data_manager import DataManager\n",
    "from environment import MultiPairForexEnv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“Š Testing data pipeline...\")\n",
    "\n",
    "# Initialize data manager\n",
    "dm = DataManager()\n",
    "print(\"âœ… DataManager initialized\")\n",
    "\n",
    "# Define CSV file paths (update these to match your uploaded files)\n",
    "csv_files = {\n",
    "    'EURUSD': 'data/EURUSD_M15.csv',\n",
    "    'AUDCHF': 'data/AUDCHF_M15.csv', \n",
    "    'USDJPY': 'data/USDJPY_M15.csv'\n",
    "}\n",
    "\n",
    "# Check which CSV files exist\n",
    "print(\"\\nğŸ“ Checking for CSV files:\")\n",
    "available_files = {}\n",
    "for pair, file_path in csv_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        size_mb = os.path.getsize(file_path) / 1e6\n",
    "        print(f\"âœ… {pair}: {file_path} ({size_mb:.1f} MB)\")\n",
    "        available_files[pair] = file_path\n",
    "    else:\n",
    "        print(f\"âŒ {pair}: {file_path} - FILE NOT FOUND\")\n",
    "\n",
    "# Load data - use CSV if available, otherwise sample data\n",
    "if available_files:\n",
    "    print(f\"\\nğŸ¯ Loading data from {len(available_files)} CSV files...\")\n",
    "    data = dm.get_multi_pair_data(csv_files=available_files)\n",
    "    print(f\"âœ… Real CSV data loaded for {len(data)} pairs\")\n",
    "    data_source = \"CSV files\"\n",
    "else:\n",
    "    print(\"\\nğŸ“Š No CSV files found, generating sample data...\")\n",
    "    data = dm.get_multi_pair_data()\n",
    "    print(f\"âœ… Sample data generated for {len(data)} pairs\")\n",
    "    data_source = \"Sample data\"\n",
    "\n",
    "for pair, df in data.items():\n",
    "    features = len([col for col in df.columns if col != 'Symbol'])\n",
    "    print(f\"   {pair}: {len(df)} candles, {features} features\")\n",
    "\n",
    "# Test environment\n",
    "print(\"\\nğŸ—ï¸ Testing trading environment...\")\n",
    "env = MultiPairForexEnv(data)\n",
    "print(f\"âœ… Environment created using {data_source}\")\n",
    "print(f\"   Action space: {env.action_space}\")\n",
    "print(f\"   Observation space: {env.observation_space.shape}\")\n",
    "\n",
    "# Quick environment test\n",
    "obs, info = env.reset()\n",
    "action = env.action_space.sample()\n",
    "obs, reward, done, truncated, info = env.step(action)\n",
    "print(f\"âœ… Environment step test: reward={reward:.1f}, balance=${info['balance']:.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Ready for PPO training with {data_source}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## ğŸš€ 4. PPO Training (12-24 hours)\n",
    "\n",
    "**Target Goal**: Train AI to make **$100 profit in 4 candles**  \n",
    "**Training Steps**: 500,000 timesteps  \n",
    "**Expected Duration**: 12-24 hours on T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data source - YOUR CSV FILES\n",
    "print(\"ğŸ“Š DATA SOURCE CONFIGURATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# IMPORTANT: Upload your CSV files to the 'data' folder first!\n",
    "# Use the file browser (folder icon on left) to upload to: data/\n",
    "#   - EURUSD_M15.csv\n",
    "#   - AUDCHF_M15.csv  \n",
    "#   - USDJPY_M15.csv\n",
    "\n",
    "csv_files = {\n",
    "    'EURUSD': 'data/EURUSD_M15.csv',\n",
    "    'AUDCHF': 'data/AUDCHF_M15.csv',  \n",
    "    'USDJPY': 'data/USDJPY_M15.csv'\n",
    "}\n",
    "\n",
    "# Check if files exist and show status\n",
    "import os\n",
    "print(\"ğŸ“ Checking CSV files:\")\n",
    "files_found = 0\n",
    "total_size_mb = 0\n",
    "\n",
    "for pair, file_path in csv_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        size_mb = os.path.getsize(file_path) / 1e6\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"âœ… {pair}: {file_path} ({size_mb:.1f} MB)\")\n",
    "        files_found += 1\n",
    "    else:\n",
    "        print(f\"âŒ {pair}: {file_path} - FILE NOT FOUND\")\n",
    "        print(f\"   ğŸ“¤ Please upload {pair}_M15.csv to the data/ folder\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Status: {files_found}/3 CSV files found\")\n",
    "print(f\"ğŸ’¾ Total data size: {total_size_mb:.1f} MB\")\n",
    "\n",
    "if files_found == 3:\n",
    "    print(\"ğŸ‰ All CSV files ready! Training will use YOUR historical data\")\n",
    "    print(\"ğŸ¯ AI will learn from REAL 10-year market patterns\")\n",
    "    print(\"ğŸ“ˆ 100,000+ candles per pair = Excellent training dataset\")\n",
    "elif files_found > 0:\n",
    "    print(f\"âš ï¸ Partial data available - will train on {files_found} pairs\")\n",
    "else:\n",
    "    print(\"âš ï¸ No CSV files found - will use sample data for testing\")\n",
    "    print(\"ğŸ“¤ To use your data:\")\n",
    "    print(\"   1. Click folder icon on left sidebar\")  \n",
    "    print(\"   2. Create 'data' folder if needed\")\n",
    "    print(\"   3. Upload your CSV files to data/ folder\")\n",
    "    print(\"   4. Refresh and re-run this cell\")\n",
    "\n",
    "print(f\"\\nğŸ”§ Ready to proceed with {'CSV data' if files_found > 0 else 'sample data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start PPO training with CSV data\n",
    "print(\"ğŸš€ STARTING PPO TRAINING FOR FOREX SYSTEM\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ¯ Goal: $100 profit in 4 candles (15-min timeframe)\")\n",
    "print(\"â° Expected time: 12-24 hours\")\n",
    "print(\"ğŸ“Š Total timesteps: 500,000\")\n",
    "\n",
    "# Check for CSV files\n",
    "import os\n",
    "csv_files = {\n",
    "    'EURUSD': 'data/EURUSD_M15.csv',\n",
    "    'AUDCHF': 'data/AUDCHF_M15.csv', \n",
    "    'USDJPY': 'data/USDJPY_M15.csv'\n",
    "}\n",
    "\n",
    "available_csv_files = {}\n",
    "for pair, file_path in csv_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        size_mb = os.path.getsize(file_path) / 1e6\n",
    "        print(f\"âœ… Found {pair}: {file_path} ({size_mb:.1f} MB)\")\n",
    "        available_csv_files[pair] = file_path\n",
    "\n",
    "if available_csv_files:\n",
    "    print(f\"\\nğŸ‰ Training on YOUR {len(available_csv_files)} CSV files!\")\n",
    "    for pair, file_path in available_csv_files.items():\n",
    "        print(f\"   {pair}: {file_path}\")\n",
    "    data_source = available_csv_files\n",
    "else:\n",
    "    print(\"\\nğŸ“Š No CSV files found - training on sample data\")\n",
    "    data_source = None\n",
    "\n",
    "print(\"\\nâš ï¸ Do NOT close this tab during training!\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Import and run training\n",
    "import sys\n",
    "sys.path.append('training')\n",
    "from train_ppo import main\n",
    "\n",
    "# Start training with CSV files (if available)\n",
    "main(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Start PPO training with %run command\n",
    "print(\"ğŸš€ STARTING PPO TRAINING FOR FOREX SYSTEM\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ¯ Goal: $100 profit in 4 candles (15-min timeframe)\")\n",
    "print(\"â° Expected time: 12-24 hours\")\n",
    "print(\"ğŸ“Š Total timesteps: 500,000\")\n",
    "print(\"\\nâš ï¸ Do NOT close this tab during training!\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Run the training script\n",
    "%run training/train_ppo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 5. Training Monitoring (Run during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard (run this in a separate cell while training)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/tensorboard\n",
    "\n",
    "print(\"ğŸ“Š TensorBoard launched above\")\n",
    "print(\"ğŸ“ˆ Monitor training progress, rewards, and loss curves\")\n",
    "print(\"ğŸ¯ Look for 'forex/goal_trades_per_rollout' to track success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training progress (run periodically)\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"ğŸ• Current time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Check for model checkpoints\n",
    "checkpoints = glob.glob('models/checkpoints/*.zip')\n",
    "if checkpoints:\n",
    "    latest = max(checkpoints, key=os.path.getctime)\n",
    "    mod_time = datetime.fromtimestamp(os.path.getmtime(latest))\n",
    "    print(f\"ğŸ’¾ Latest checkpoint: {latest}\")\n",
    "    print(f\"   Created: {mod_time.strftime('%H:%M:%S')}\")\n",
    "else:\n",
    "    print(\"ğŸ’¾ No checkpoints yet...\")\n",
    "\n",
    "# Check log files\n",
    "if os.path.exists('logs/evaluations'):\n",
    "    eval_files = os.listdir('logs/evaluations')\n",
    "    print(f\"ğŸ“Š Evaluation files: {len(eval_files)}\")\n",
    "\n",
    "print(\"\\nğŸ”„ Training is running... Check TensorBoard above for real-time metrics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 6. Download Trained Model (After training completes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download final trained model\n",
    "import os\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"ğŸ“¦ Preparing model for download...\")\n",
    "\n",
    "# Create download package\n",
    "download_files = [\n",
    "    'models/final/forex_ppo_model.zip',\n",
    "    'config/training.yaml'\n",
    "]\n",
    "\n",
    "# Check if training completed\n",
    "model_path = 'models/final/forex_ppo_model.zip'\n",
    "if os.path.exists(model_path):\n",
    "    size_mb = os.path.getsize(model_path) / 1e6\n",
    "    print(f\"âœ… Final model ready: {model_path} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Download the model\n",
    "    files.download(model_path)\n",
    "    \n",
    "    # Download config\n",
    "    if os.path.exists('config/training.yaml'):\n",
    "        files.download('config/training.yaml')\n",
    "    \n",
    "    print(\"\\nğŸ‰ Model downloaded successfully!\")\n",
    "    print(\"ğŸ“ Files downloaded:\")\n",
    "    print(\"   - forex_ppo_model.zip (trained model)\")\n",
    "    print(\"   - training.yaml (configuration)\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Model not found. Training may not be complete yet.\")\n",
    "    \n",
    "    # Check for latest checkpoint\n",
    "    import glob\n",
    "    checkpoints = glob.glob('models/checkpoints/*.zip')\n",
    "    if checkpoints:\n",
    "        latest = max(checkpoints, key=os.path.getctime)\n",
    "        print(f\"ğŸ’¾ Latest checkpoint available: {latest}\")\n",
    "        download_latest = input(\"Download latest checkpoint? (y/n): \")\n",
    "        if download_latest.lower() == 'y':\n",
    "            files.download(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## ğŸ“Š 7. Training Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training results summary\n",
    "print(\"ğŸ† FOREX TRADING SYSTEM TRAINING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ¯ Goal: AI that makes $100 profit in 4 candles\")\n",
    "print(\"ğŸ¤– Algorithm: PPO with custom reward function\")\n",
    "print(\"ğŸ“Š Training: 500k timesteps on GPU\")\n",
    "print(\"\\nğŸ“ˆ Next Steps:\")\n",
    "print(\"1. Download the trained model (forex_ppo_model.zip)\")\n",
    "print(\"2. Use it locally for Phase 4: Inference Engine\")\n",
    "print(\"3. Build the desktop UI for live trading\")\n",
    "print(\"\\nğŸ‰ Your AI forex trader is ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}